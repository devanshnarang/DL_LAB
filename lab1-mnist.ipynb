{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-16T03:45:53.050115Z","iopub.execute_input":"2025-01-16T03:45:53.050480Z","iopub.status.idle":"2025-01-16T03:45:53.073471Z","shell.execute_reply.started":"2025-01-16T03:45:53.050451Z","shell.execute_reply":"2025-01-16T03:45:53.072470Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mnist-dataset/train-images.idx3-ubyte\n/kaggle/input/mnist-dataset/t10k-labels.idx1-ubyte\n/kaggle/input/mnist-dataset/t10k-images.idx3-ubyte\n/kaggle/input/mnist-dataset/train-labels.idx1-ubyte\n/kaggle/input/mnist-dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\n/kaggle/input/mnist-dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\n/kaggle/input/mnist-dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte\n/kaggle/input/mnist-dataset/train-images-idx3-ubyte/train-images-idx3-ubyte\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\n\ndef initialize_weights(layer_sizes):\n    np.random.seed(42)\n    weights = {}\n    for i in range(len(layer_sizes) - 1):\n        weights[f\"W{i+1}\"] = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2. / layer_sizes[i])\n        weights[f\"b{i+1}\"] = np.zeros((1, layer_sizes[i+1]))\n    return weights\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\ndef softmax(z):   #why\n    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n\ndef forward_propagation(X, weights, num_layers):\n    cache = {\"A0\": X}\n    A = X\n    for i in range(1, num_layers):\n        Z = np.dot(A, weights[f\"W{i}\"]) + weights[f\"b{i}\"]\n        A = sigmoid(Z)\n        cache[f\"Z{i}\"] = Z\n        cache[f\"A{i}\"] = A\n\n    # Output layer\n    Z = np.dot(A, weights[f\"W{num_layers}\"]) + weights[f\"b{num_layers}\"]\n    A = softmax(Z)\n    cache[f\"Z{num_layers}\"] = Z\n    cache[f\"A{num_layers}\"] = A\n    return A, cache\n\ndef compute_loss(y_true, y_pred):\n    m = y_true.shape[0]\n    log_probs = -np.log(y_pred[range(m), y_true])    # \n    loss = np.sum(log_probs) / m\n    return loss\n\ndef backward_propagation(X, y, weights, cache, num_layers):\n    m = X.shape[0]\n    grads = {}\n    y_onehot = np.zeros_like(cache[f\"A{num_layers}\"])\n    y_onehot[np.arange(m), y] = 1\n\n    # Output layer gradient\n    dZ = cache[f\"A{num_layers}\"] - y_onehot\n    grads[f\"dW{num_layers}\"] = np.dot(cache[f\"A{num_layers-1}\"].T, dZ) / m\n    grads[f\"db{num_layers}\"] = np.sum(dZ, axis=0, keepdims=True) / m\n\n    # Hidden layers gradients\n    for i in range(num_layers - 1, 0, -1):\n        dZ = np.dot(dZ, weights[f\"W{i+1}\"].T) * cache[f\"A{i}\"] * (1 - cache[f\"A{i}\"])\n        grads[f\"dW{i}\"] = np.dot(cache[f\"A{i-1}\"].T, dZ) / m\n        grads[f\"db{i}\"] = np.sum(dZ, axis=0, keepdims=True) / m\n\n    return grads\n\ndef update_weights(weights, grads, learning_rate, num_layers):\n    for i in range(1, num_layers + 1):\n        weights[f\"W{i}\"] -= learning_rate * grads[f\"dW{i}\"]\n        weights[f\"b{i}\"] -= learning_rate * grads[f\"db{i}\"]\n    return weights\n\ndef train(X, y, layer_sizes, epochs, learning_rate):\n    num_layers = len(layer_sizes) - 1\n    weights = initialize_weights(layer_sizes)\n\n    for epoch in range(epochs):\n        y_pred, cache = forward_propagation(X, weights, num_layers)\n        loss = compute_loss(y, y_pred)\n        if epoch % 10 == 0:\n            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n\n        grads = backward_propagation(X, y, weights, cache, num_layers)\n        weights = update_weights(weights, grads, learning_rate, num_layers)\n\n    return weights\n\ndef predict(X, weights, num_layers):\n    y_pred, _ = forward_propagation(X, weights, num_layers)\n    return np.argmax(y_pred, axis=1)\n\nlayer_sizes = [784, 128, 64, 10]\n\nX_train = load_mnist_images('/kaggle/input/mnist-dataset/train-images.idx3-ubyte')\ny_train = load_mnist_labels('/kaggle/input/mnist-dataset/train-labels.idx1-ubyte')\nX_test = load_mnist_images('/kaggle/input/mnist-dataset/t10k-images.idx3-ubyte')\ny_test = load_mnist_labels('/kaggle/input/mnist-dataset/t10k-labels.idx1-ubyte')\n\nweights = train(X_train, y_train, layer_sizes, epochs=300, learning_rate=0.1)\n\ny_pred = predict(X_test, weights, num_layers=len(layer_sizes)-1)\naccuracy = np.mean(y_pred == y_test)\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T03:45:53.074655Z","iopub.execute_input":"2025-01-16T03:45:53.074947Z","iopub.status.idle":"2025-01-16T03:46:13.667384Z","shell.execute_reply.started":"2025-01-16T03:45:53.074923Z","shell.execute_reply":"2025-01-16T03:46:13.665918Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 20.42%\n","output_type":"stream"}],"execution_count":8}]}